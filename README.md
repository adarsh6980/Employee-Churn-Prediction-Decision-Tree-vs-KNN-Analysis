# ğŸ¯ Employee Churn Prediction - Decision Tree vs KNN

> **A Machine Learning Approach to HR Retention Strategy**  
> Predicting employee attrition using Decision Trees and K-Nearest Neighbors algorithms with 84.81% accuracy.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/downloads/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0%2B-orange)](https://scikit-learn.org/)
[![Status: Complete](https://img.shields.io/badge/Status-Complete-brightgreen)](https://github.com)

---
## ğŸ“‹ Table of Contents
- [Overview](#-overview)
- [Dataset](#dataset)
- [Project Structure](#project-structure)
- [Installation & Setup](#installation--setup)
- [Models Overview](#models-overview)
- [Key Results](#key-results)
- [Data Exploration](#data-exploration)
- [Model Performance](#model-performance)
- [Business Insights](#business-insights)
- [Usage Guide](#usage-guide)
- [Results & Recommendations](#results--recommendations)
- [Tech Stack](#tech-stack)
- [Contributing](#contributing)
- [License](#license)

---
## ğŸ¯ Overview
**Problem Statement:** Predict which employees are at risk of leaving the organization to enable proactive retention strategies.

**Business Impact:** Employee turnover costs organizations ~200% of annual salary per employee. Identifying at-risk employees early can save **$40,000-$100,000+ per prevented departure**.

**Solution:** Compare two machine learning algorithms:
- **Decision Tree**: Interpretable with clear decision rules
- **K-Nearest Neighbors**: High accuracy with 84.81% performance

**Key Achievement:** Successfully identified top 5 churn predictors accounting for 40% of decision-making:
1. Total Working Years (16.5%)
2. Monthly Income (13.6%)
3. Age (10.0%)
4. Overtime (7.9%)
5. Stock Options (7.6%)

---
## ğŸ“ Project Structure
```
Employee-Churn-Prediction-Decision-Tree-vs-KNN-Analysis/
â”œâ”€â”€ data/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ 01_target_distribution.png
â”‚   â”œâ”€â”€ 02_age_vs_attrition.png
â”‚   â”œâ”€â”€ 03_tenure_vs_attrition.png
â”‚   â”œâ”€â”€ 04_correlation_heatmap.png
â”‚   â”œâ”€â”€ 05_age_vs_attrition.png
â”‚   â”œâ”€â”€ 06_dt_feature_importance.png
â”‚   â”œâ”€â”€ 7_dt_tree_visualization.png
â”‚   â”œâ”€â”€ 8_dt_cv_scores.png
â”‚   â”œâ”€â”€ 9_dt_confusion_matrix.png
â”‚   â”œâ”€â”€ 10_dt_roc_curve.png
â”‚   â”œâ”€â”€ 11_knn_tuning.png
â”‚   â”œâ”€â”€ 12_knn_cv_scores.png
â”‚   â”œâ”€â”€ 13_knn_confusion_matrix.png
â”‚   â”œâ”€â”€ 14_model_comparison_roc.png
â”‚   â””â”€â”€ 15_model_comparison.png
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---
## ğŸ“Š Data Exploration

### Plot 1: Target Distribution
![Target Distribution](plots/01_target_distribution.png)

### Plot 2: Age vs Attrition
![Age vs Attrition](plots/02_age_vs_attrition.png)

### Plot 3: Tenure vs Attrition
![Tenure vs Attrition](plots/03_tenure_vs_attrition.png)

### Plot 4: Correlation Heatmap
![Correlation Heatmap](plots/04_correlation_heatmap.png)

### Plot 5: Age vs Attrition (Binned/Variant)
![Age vs Attrition (Variant)](plots/05_age_vs_attrition.png)

---
## ğŸ§  Models Overview
- Decision Tree Classifier
- K-Nearest Neighbors Classifier

---
## ğŸ§ª Model Performance

### Decision Tree
- Feature Importance
![DT Feature Importance](plots/06_dt_feature_importance.png)

- Cross-Validation Scores
![DT CV Scores](plots/8_dt_cv_scores.png)

- Confusion Matrix
![DT Confusion Matrix](plots/9_dt_confusion_matrix.png)

- ROC Curve
![DT ROC Curve](plots/10_dt_roc_curve.png)

- Tree Structure
![DT Tree Structure](plots/7_dt_tree_visualization.png)

### KNN
- Hyperparameter Tuning
![KNN Tuning](plots/11_knn_tuning.png)

- Cross-Validation Scores
![KNN CV Scores](plots/12_knn_cv_scores.png)

- Confusion Matrix
![KNN Confusion Matrix](plots/13_knn_confusion_matrix.png)

### Model Comparison
- ROC Curve Comparison
![Model Comparison ROC](plots/14_model_comparison_roc.png)

- Overall Metrics Comparison
![Model Comparison](plots/15_model_comparison.png)

---
## ğŸ“Š Project Statistics
- **Total Employees Analyzed:** 1,470
- **Features Engineering:** 34 â†’ 51
- **Models Developed:** 2 (Decision Tree + KNN)
- **Visualizations Created:** 15+
- **Cross-Validation Folds:** 5
- **Hyperparameters Tuned:** 7+
- **Training Time:** <5 minutes
- **Prediction Time:** <10ms per employee

---
## ğŸ“ Learnings & Insights
### Key Technical Learnings
âœ… Importance of stratified sampling for imbalanced datasets  
âœ… Feature scaling critical for distance-based algorithms (KNN)  
âœ… Trade-offs between model interpretability vs accuracy  
âœ… Cross-validation for robust performance estimation  
âœ… Hyperparameter tuning for optimal model selection  

### Business Learnings
âœ… First 2 years crucial for retention  
âœ… Compensation directly impacts churn  
âœ… Overtime correlates with higher attrition  
âœ… Age and experience are strong predictors  
âœ… Early intervention more cost-effective than reactive approach  

---
## ğŸ§° Tech Stack
- Python, pandas, NumPy, scikit-learn, Matplotlib/Seaborn, Jupyter

---
## ğŸš€ Usage Guide
- Install dependencies: `pip install -r requirements.txt`
- Run notebooks in `notebooks/` to reproduce results

---
## âœ… Results & Recommendations
- Decision Tree provides interpretability for HR actions
- KNN offers competitive accuracy with proper scaling
- Focus retention efforts on top predictors identified

---
## â­ Acknowledgments
Special thanks to:
- IBM for the HR Analytics dataset
- Kaggle community for insights
- Scikit-learn team for excellent ML library
- TUS Athlone for academic guidance

---
<div align="center">

### Made with â¤ï¸ by Adarsh Ramakrishna

â­ If this project helps you, please star the repository!

[â¬† Back to Top](#-employee-churn-prediction---decision-tree-vs-knn)

</div>
